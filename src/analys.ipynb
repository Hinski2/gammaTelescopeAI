{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "my ai project about magic telescope. Link to data: https://archive.ics.uci.edu/dataset/159/magic+gamma+telescope , more about data in file located: /data/magic04.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fLength</th>\n",
       "      <th>fWidth</th>\n",
       "      <th>fSize</th>\n",
       "      <th>fConc</th>\n",
       "      <th>fConc1</th>\n",
       "      <th>fAsym</th>\n",
       "      <th>fM3Long</th>\n",
       "      <th>fM3Trans</th>\n",
       "      <th>fAlpha</th>\n",
       "      <th>fDist</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28.7967</td>\n",
       "      <td>16.0021</td>\n",
       "      <td>2.6449</td>\n",
       "      <td>0.3918</td>\n",
       "      <td>0.1982</td>\n",
       "      <td>27.7004</td>\n",
       "      <td>22.0110</td>\n",
       "      <td>-8.2027</td>\n",
       "      <td>40.0920</td>\n",
       "      <td>81.8828</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31.6036</td>\n",
       "      <td>11.7235</td>\n",
       "      <td>2.5185</td>\n",
       "      <td>0.5303</td>\n",
       "      <td>0.3773</td>\n",
       "      <td>26.2722</td>\n",
       "      <td>23.8238</td>\n",
       "      <td>-9.9574</td>\n",
       "      <td>6.3609</td>\n",
       "      <td>205.2610</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>162.0520</td>\n",
       "      <td>136.0310</td>\n",
       "      <td>4.0612</td>\n",
       "      <td>0.0374</td>\n",
       "      <td>0.0187</td>\n",
       "      <td>116.7410</td>\n",
       "      <td>-64.8580</td>\n",
       "      <td>-45.2160</td>\n",
       "      <td>76.9600</td>\n",
       "      <td>256.7880</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.8172</td>\n",
       "      <td>9.5728</td>\n",
       "      <td>2.3385</td>\n",
       "      <td>0.6147</td>\n",
       "      <td>0.3922</td>\n",
       "      <td>27.2107</td>\n",
       "      <td>-6.4633</td>\n",
       "      <td>-7.1513</td>\n",
       "      <td>10.4490</td>\n",
       "      <td>116.7370</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75.1362</td>\n",
       "      <td>30.9205</td>\n",
       "      <td>3.1611</td>\n",
       "      <td>0.3168</td>\n",
       "      <td>0.1832</td>\n",
       "      <td>-5.5277</td>\n",
       "      <td>28.5525</td>\n",
       "      <td>21.8393</td>\n",
       "      <td>4.6480</td>\n",
       "      <td>356.4620</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    fLength    fWidth   fSize   fConc  fConc1     fAsym  fM3Long  fM3Trans  \\\n",
       "0   28.7967   16.0021  2.6449  0.3918  0.1982   27.7004  22.0110   -8.2027   \n",
       "1   31.6036   11.7235  2.5185  0.5303  0.3773   26.2722  23.8238   -9.9574   \n",
       "2  162.0520  136.0310  4.0612  0.0374  0.0187  116.7410 -64.8580  -45.2160   \n",
       "3   23.8172    9.5728  2.3385  0.6147  0.3922   27.2107  -6.4633   -7.1513   \n",
       "4   75.1362   30.9205  3.1611  0.3168  0.1832   -5.5277  28.5525   21.8393   \n",
       "\n",
       "    fAlpha     fDist class  \n",
       "0  40.0920   81.8828     g  \n",
       "1   6.3609  205.2610     g  \n",
       "2  76.9600  256.7880     g  \n",
       "3  10.4490  116.7370     g  \n",
       "4   4.6480  356.4620     g  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relative_path = '../data/magic04.data'\n",
    "cols = [\"fLength\", \"fWidth\", \"fSize\", \"fConc\", \"fConc1\", \"fAsym\", \"fM3Long\", \"fM3Trans\", \"fAlpha\", \"fDist\", \"class\"]\n",
    "df = pd.read_csv(relative_path, names=cols)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"class\"] = (df[\"class\"] == \"g\").astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for label in cols[:-1]:\n",
    "#     plt.hist(df[df[\"class\"] == 1][label], color='blue', label='gamma', alpha=0.7, density=True)\n",
    "#     plt.hist(df[df[\"class\"] == 0][label], color='red', label='hadron', alpha=0.7, density=True)\n",
    "#     plt.title(label)\n",
    "#     plt.ylabel(\"probablitity\")\n",
    "#     plt.xlabel(label)\n",
    "#     plt.legend()\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## spliting data across train, valid, test datastes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13314\n",
      "2853\n",
      "2853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kuba/miniconda3/envs/tf/lib/python3.9/site-packages/numpy/core/fromnumeric.py:57: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "train, valid, test = np.split(df.sample(frac = 1), [int(0.7 * len(df)), int(0.85 * len(df))])\n",
    "print(len(train))\n",
    "print(len(valid))\n",
    "print(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_data(dataframe, oversample=False):\n",
    "    x = dataframe[dataframe.columns[:-1]].values\n",
    "    y = dataframe[dataframe.columns[-1]].values\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    x = scaler.fit_transform(x)\n",
    "   \n",
    "    if oversample:\n",
    "        ros = RandomOverSampler()\n",
    "        x, y = ros.fit_resample(x, y)\n",
    "         \n",
    "    data = np.hstack((x, np.reshape(y, (-1, 1))))\n",
    "    \n",
    "    return data, x, y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, x_train, y_train = scale_data(train, oversample=True)\n",
    "valid, x_valid, y_valid = scale_data(valid, oversample=False)\n",
    "test, x_test, y_test = scale_data(test, oversample=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-nearest nighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_model = knn_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.72      0.73      1032\n",
      "           1       0.84      0.86      0.85      1821\n",
      "\n",
      "    accuracy                           0.81      2853\n",
      "   macro avg       0.79      0.79      0.79      2853\n",
      "weighted avg       0.81      0.81      0.81      2853\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = knn_model.predict(x_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_model = GaussianNB()\n",
    "nb_model = nb_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.42      0.53      1032\n",
      "           1       0.73      0.91      0.81      1821\n",
      "\n",
      "    accuracy                           0.73      2853\n",
      "   macro avg       0.73      0.66      0.67      2853\n",
      "weighted avg       0.73      0.73      0.71      2853\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = nb_model.predict(x_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_model = LogisticRegression()\n",
    "log_model = log_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.72      0.71      1032\n",
      "           1       0.84      0.82      0.83      1821\n",
      "\n",
      "    accuracy                           0.79      2853\n",
      "   macro avg       0.77      0.77      0.77      2853\n",
      "weighted avg       0.79      0.79      0.79      2853\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = log_model.predict(x_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model = SVC()\n",
    "svm_model = svm_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.77      0.78      1032\n",
      "           1       0.87      0.89      0.88      1821\n",
      "\n",
      "    accuracy                           0.85      2853\n",
      "   macro avg       0.84      0.83      0.83      2853\n",
      "weighted avg       0.85      0.85      0.85      2853\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = svm_model.predict(x_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-07 20:45:52.527043: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-10-07 20:45:52.807622: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-07 20:45:53.792129: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-07 20:45:55.055394: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-07 20:45:55.223669: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.config.list_physical_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funkcja do rysowania wykresu straty (loss).\n",
    "def plot(history):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    ax1.plot(history.history['loss'], label='Strata (Loss)')\n",
    "    ax1.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    ax1.set_xlabel('Epoka')\n",
    "    ax1.set_ylabel('Strata')\n",
    "    ax1.grid(True)\n",
    "    ax1.legend()\n",
    "\n",
    "    ax2.plot(history.history['accuracy'], label='Dokładność (Accuracy)')\n",
    "    ax2.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    ax2.set_xlabel('Epoka')\n",
    "    ax2.set_ylabel('Dokładność')\n",
    "    ax2.grid(True)\n",
    "    ax2.legend()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(x_train, y_train, num_nodes, dropout_prob, lr, batch_size, epochs):\n",
    "    nn_model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(num_nodes, activation='relu', input_shape=(10,)),\n",
    "        tf.keras.layers.Dropout(dropout_prob),\n",
    "        tf.keras.layers.Dense(num_nodes, activation='relu'),\n",
    "        tf.keras.layers.Dropout(dropout_prob),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    nn_model.compile(optimizer=tf.keras.optimizers.Adam(lr), loss='binary_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "    \n",
    "    with tf.device('/device:GPU:0'):\n",
    "        history = nn_model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, validation_split=0.2, verbose=0)\n",
    "        \n",
    "    return nn_model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nodes 32, droput 0, lr 0.001, batch size 64, \n",
      "90/90 [==============================] - 0s 783us/step - loss: 0.2918 - accuracy: 0.8787\n",
      "nodes 32, droput 0, lr 0.001, batch size 128, \n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.2996 - accuracy: 0.8777\n",
      "nodes 32, droput 0, lr 0.01, batch size 64, \n",
      "90/90 [==============================] - 0s 904us/step - loss: 0.3693 - accuracy: 0.8661\n",
      "nodes 32, droput 0, lr 0.01, batch size 128, \n",
      "90/90 [==============================] - 0s 859us/step - loss: 0.3384 - accuracy: 0.8710\n",
      "nodes 32, droput 0.2, lr 0.001, batch size 64, \n",
      "90/90 [==============================] - 0s 868us/step - loss: 0.2903 - accuracy: 0.8798\n",
      "nodes 32, droput 0.2, lr 0.001, batch size 128, \n",
      "90/90 [==============================] - 0s 891us/step - loss: 0.2899 - accuracy: 0.8787\n",
      "nodes 32, droput 0.2, lr 0.01, batch size 64, \n",
      "90/90 [==============================] - 0s 933us/step - loss: 0.2921 - accuracy: 0.8836\n",
      "nodes 32, droput 0.2, lr 0.01, batch size 128, \n",
      "90/90 [==============================] - 0s 743us/step - loss: 0.2859 - accuracy: 0.8829\n",
      "nodes 64, droput 0, lr 0.001, batch size 64, \n",
      "90/90 [==============================] - 0s 732us/step - loss: 0.3103 - accuracy: 0.8805\n",
      "nodes 64, droput 0, lr 0.001, batch size 128, \n",
      "90/90 [==============================] - 0s 916us/step - loss: 0.2944 - accuracy: 0.8798\n",
      "nodes 64, droput 0, lr 0.01, batch size 64, \n",
      "90/90 [==============================] - 0s 955us/step - loss: 0.4859 - accuracy: 0.8658\n",
      "nodes 64, droput 0, lr 0.01, batch size 128, \n",
      "90/90 [==============================] - 0s 873us/step - loss: 0.5502 - accuracy: 0.8626\n",
      "nodes 64, droput 0.2, lr 0.001, batch size 64, \n",
      "90/90 [==============================] - 0s 959us/step - loss: 0.2822 - accuracy: 0.8836\n",
      "nodes 64, droput 0.2, lr 0.001, batch size 128, \n",
      "90/90 [==============================] - 0s 975us/step - loss: 0.2839 - accuracy: 0.8815\n",
      "nodes 64, droput 0.2, lr 0.01, batch size 64, \n",
      "90/90 [==============================] - 0s 959us/step - loss: 0.2922 - accuracy: 0.8801\n",
      "nodes 64, droput 0.2, lr 0.01, batch size 128, \n",
      "90/90 [==============================] - 0s 970us/step - loss: 0.2918 - accuracy: 0.8777\n"
     ]
    }
   ],
   "source": [
    "epochs=100\n",
    "least_val_loss = float('inf')\n",
    "least_loss_model = None\n",
    "\n",
    "for num_nodes in [32, 64]:\n",
    "    for dropout_prob in [0, 0.2]:\n",
    "        for lr in [0.001, 0.01]:\n",
    "            for batch_size in [64, 128]:\n",
    "                print(f\"nodes {num_nodes}, droput {dropout_prob}, lr {lr}, batch size {batch_size}, \")\n",
    "                model, history = train_model(x_train, y_train, num_nodes, dropout_prob, lr, batch_size, epochs)\n",
    "                # plot(history)\n",
    "                evaluation = model.evaluate(x_valid, y_valid)\n",
    "                val_loss = evaluation[0]  \n",
    "                if val_loss < least_val_loss:\n",
    "                    least_val_loss = val_loss\n",
    "                    least_loss_model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 0s 664us/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = least_loss_model.predict(x_test)\n",
    "y_pred = (y_pred > 0.5).astype(int).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.71      0.79      1032\n",
      "           1       0.85      0.96      0.90      1821\n",
      "\n",
      "    accuracy                           0.87      2853\n",
      "   macro avg       0.88      0.83      0.85      2853\n",
      "weighted avg       0.87      0.87      0.86      2853\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
